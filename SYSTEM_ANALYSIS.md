# Stra≈ºnik Prawa - Kompleksowa Analiza Systemu

**Data analizy:** 2 stycznia 2026  
**Wersja:** 2.0 (Refaktoryzacja Multi-Worker)

---

## üìã Executive Summary

System **Stra≈ºnik Prawa** to aplikacja monitoringu akt√≥w prawnych z 10 ≈∫r√≥de≈Ç danych (ELI, RSS, Scrapers). Obecna architektura ma **3 krytyczne problemy**:

1. **Blokowanie scraper√≥w** - wszystkie ≈∫r√≥d≈Ça wykonujƒÖ siƒô sekwencyjnie, nawet gdy jedno zawiedzie
2. **Duplikaty danych** - brak unikalnych kluczy per ≈∫r√≥d≈Ço, mo≈ºliwe wielokrotne zapisy tego samego dokumentu
3. **NiewystarczajƒÖca historia** - frontend ma filtry do 90 dni, ale scrapers pobierajƒÖ tylko 30-90 dni (brak bufora)

### Proponowane rozwiƒÖzanie
- **3 osobne workery** (ELI, RSS, NFZ) uruchamiane r√≥wnolegle
- **3 dedykowane endpointy** (`/updates/eli`, `/updates/rss`, `/updates/nfz`)
- **Unikalne composite keys** w bazie danych (source + docId + date)
- **Rozszerzenie okna czasowego** do 150 dni (bufor dla filtr√≥w 90d)

---

## üèóÔ∏è Obecna Architektura

### Stack Technologiczny
**Backend:**
- Runtime: Node.js 20+ z TypeScript 5.3
- Framework: Express 4.18
- ORM: Prisma 5.22 + SQLite
- Scheduler: node-cron (co 10 min)
- Scrapers: axios + xml2js + cheerio

**Frontend:**
- Framework: React 19.2 (TSX)
- Bundler: Vite 6.2
- Styling: Tailwind CSS (CDN)
- State: useState + LocalStorage
- API: fetch z 15s timeout

### ≈πr√≥d≈Ça Danych (10 total)

| ID | Nazwa | Typ | URL | Status |
|----|-------|-----|-----|--------|
| `eli-sejm-du` | Sejm DU | ELI/JSON | https://api.sejm.gov.pl/eli/acts/DU | ‚úÖ |
| `eli-sejm-mp` | Sejm MP | ELI/JSON | https://api.sejm.gov.pl/eli/acts/MP | ‚úÖ |
| `eli-mz` | Ministerstwo Zdrowia | ELI/XML | https://dziennikmz.mz.gov.pl/api/eli/acts | ‚ö†Ô∏è |
| `eli-mswia` | MSWiA | ELI/XML | https://edziennik.mswia.gov.pl/api/eli/acts | ‚ö†Ô∏è |
| `eli-men` | Edukacja | ELI/XML | https://dziennik.men.gov.pl/api/eli/acts | ‚ö†Ô∏è |
| `eli-mon` | MON | ELI/XML | https://dziennik.mon.gov.pl/api/eli/acts | ‚ö†Ô∏è |
| `eli-nbp` | NBP | ELI/XML | https://dzu.nbp.pl/api/eli/acts | ‚ö†Ô∏è |
| `rss-zus` | ZUS Aktualno≈õci | RSS | https://www.zus.pl/o-zus/aktualnosci | ‚úÖ |
| `rss-cez` | e-Zdrowie CEZ | RSS | https://www.ezdrowie.gov.pl | ‚úÖ |
| `nfz` | NFZ ZarzƒÖdzenia | Scraper | https://www.nfz.gov.pl/zarzadzenia-prezesa/ | ‚ö†Ô∏è |

**Legenda status√≥w:**
- ‚úÖ Dzia≈Ça stabilnie
- ‚ö†Ô∏è Okresowe timeouty / b≈Çƒôdy parsowania

---

## üêõ Zidentyfikowane Problemy

### Problem 1: Sekwencyjne Blokowanie Scraper√≥w

**Lokalizacja:** `backend/src/services/dataService.ts:21-27`

```typescript
// PROBLEM: Promise.allSettled blokuje g≈Ç√≥wny wƒÖtek
const [eliSources, sejmApi, zusRss, cezRss, nfz] = await Promise.allSettled([
  scrapeAllELI(),      // 5-10s (7 ≈∫r√≥de≈Ç XML)
  scrapeSejmAPI(),     // 2-3s
  scrapeRSS(...),      // 2-5s
  scrapeRSS(...),      // 2-5s
  scrapeNFZ()          // 3-7s
]);
```

**Skutek:**
- Ca≈Çkowity czas refresh: **15-32 sekundy** (suma najd≈Çu≈ºszych)
- Je≈õli jedno ≈∫r√≥d≈Ço timeout (30s), ca≈Ça pƒôtka czeka
- Scheduler blokuje siƒô co 10 minut

**Konsekwencje biznesowe:**
- U≈ºytkownik czeka >30s na dane po klikniƒôciu "Pobierz dane"
- Backend nie odpowiada podczas scrapingu
- Frontend wy≈õwietla b≈ÇƒÖd "B≈ÇƒÖd systemu ingestii"

### Problem 2: Brak Deduplikacji

**Lokalizacja:** `backend/prisma/schema.prisma:10-28`

```prisma
model LegalFact {
  id String @id  // ‚ùå PROBLEM: UUID nie gwarantuje unikalno≈õci per dokument
  // ...
  @@index([date])
  @@index([ingestMethod])
}
```

**Przyk≈Çad duplikatu:**
- Dokument "RozporzƒÖdzenie MZ 2025/1" z dnia 2025-01-02
- Pierwsze pobranie: `id = "eli-mz-2025-1-1735824000"`
- Drugie pobranie (scheduler): `id = "eli-mz-2025-1-1735824600"`
- **Wynik:** 2 identyczne rekordy w bazie

**Statystyki z produkcji:**
- Baza danych: **legal.db** (280 KB)
- Estymowane duplikaty: **15-20%** (brak unikalnego constrainta)

### Problem 3: NiewystarczajƒÖca Historia

**Lokalizacja:** `backend/src/scrapers/eli/eliClient.ts:39`

```typescript
// PROBLEM: Tylko 30 dni historii
async fetchRecentDocuments(days: number = 30) { ... }
```

**Wymaganie:**
- Frontend: filtry 7d, 30d, **90d**
- Backend: scrapers **30-90d** (zale≈ºnie od ≈∫r√≥d≈Ça)
- **Gap:** Brak bufora - dokument sprzed 91 dni zniknie z widoku 90d

**Matematyka:**
```
Wymagane minimum = 90d (filtr) + 30d (bufor na op√≥≈∫nienia) = 120 dni
Aktualne: 30-90 dni
Deficit: 30-90 dni
```

---

## üéØ Architektura Docelowa (v2.0)

### Koncepcja Multi-Worker

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               Express Server (Port 5554)            ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  GET /api/v1/health        ‚Üí Health check          ‚îÇ
‚îÇ  GET /api/v1/updates       ‚Üí Merged view (all)     ‚îÇ
‚îÇ  GET /api/v1/updates/eli   ‚Üí ELI sources only      ‚îÇ
‚îÇ  GET /api/v1/updates/rss   ‚Üí RSS feeds only        ‚îÇ
‚îÇ  GET /api/v1/updates/nfz   ‚Üí NFZ scraper only      ‚îÇ
‚îÇ  POST /api/v1/export       ‚Üí Export selected       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì                ‚Üì              ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Worker 1 ‚îÇ      ‚îÇ Worker 2 ‚îÇ   ‚îÇ Worker 3 ‚îÇ
    ‚îÇ   ELI    ‚îÇ      ‚îÇ   RSS    ‚îÇ   ‚îÇ   NFZ    ‚îÇ
    ‚îÇ (7 srcs) ‚îÇ      ‚îÇ (2 srcs) ‚îÇ   ‚îÇ (1 src)  ‚îÇ
    ‚îÇ  10 min  ‚îÇ      ‚îÇ  15 min  ‚îÇ   ‚îÇ  20 min  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì                ‚Üì              ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ          SQLite Database (legal.db)             ‚îÇ
    ‚îÇ                                                 ‚îÇ
    ‚îÇ  LegalFact:                                     ‚îÇ
    ‚îÇ    - compositeKey (source + docId + date) PK    ‚îÇ
    ‚îÇ    - ingestMethod (eli | rss | scraper)         ‚îÇ
    ‚îÇ    - sourceId (eli-sejm-du, rss-zus, etc.)      ‚îÇ
    ‚îÇ    - date (ISO 8601)                            ‚îÇ
    ‚îÇ    - title, summary, ...                        ‚îÇ
    ‚îÇ                                                 ‚îÇ
    ‚îÇ  @@unique([sourceId, docId, date])              ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Nowy Model Danych

```prisma
model LegalFact {
  compositeKey       String   @id  // "${sourceId}:${docId}:${date}"
  sourceId           String         // 'eli-sejm-du', 'rss-zus', 'nfz'
  docId              String         // Unikalny ID dokumentu per ≈∫r√≥d≈Ço
  ingestMethod       String         // 'eli', 'rss', 'scraper'
  
  eliUri             String?
  title              String
  summary            String
  date               String
  impact             String
  category           String
  legalStatus        String
  officialRationale  String
  sourceUrl          String
  
  createdAt          DateTime @default(now())
  updatedAt          DateTime @updatedAt

  @@unique([sourceId, docId, date])  // Zapobiega duplikatom
  @@index([date])
  @@index([ingestMethod])
  @@index([sourceId])
}
```

### Nowe Endpointy API

**1. GET /api/v1/updates/eli?range=90d**
- Tylko ≈∫r√≥d≈Ça ELI (Sejm DU/MP + ministerstwa + NBP)
- Parametry: `range` (7d/30d/90d/120d), `source` (opcjonalnie)
- Sortowanie: data malejƒÖco

**2. GET /api/v1/updates/rss?range=30d**
- Tylko feedy RSS (ZUS + CEZ)
- Parametry: `range`, `source`

**3. GET /api/v1/updates/nfz?range=90d**
- Tylko scraper NFZ
- Parametry: `range`

**4. GET /api/v1/updates?range=90d** (merged)
- Wszystkie ≈∫r√≥d≈Ça po≈ÇƒÖczone
- Parametry: `range`, `method` (eli/rss/scraper)
- Backward compatible z obecnym frontendem

---

## üì¶ Plan Implementacji

### Faza 1: Refaktoryzacja Bazy Danych (30 min)

**Pliki do modyfikacji:**
- `backend/prisma/schema.prisma` - nowy model LegalFact
- `backend/prisma/migrations/` - migracja dodajƒÖca unique constraint

**Kroki:**
1. Backup obecnej bazy: `cp backend/legal.db backend/legal.db.backup`
2. Dodaj pole `compositeKey`, `sourceId`, `docId`
3. Migracja: `npx prisma migrate dev --name add_deduplication`
4. Regeneruj klienta: `npx prisma generate`

**Walidacja:**
```sql
-- Sprawd≈∫ duplikaty przed migracjƒÖ
SELECT sourceId, docId, date, COUNT(*) 
FROM LegalFact 
GROUP BY sourceId, docId, date 
HAVING COUNT(*) > 1;
```

### Faza 2: Worker Service (60 min)

**Nowe pliki:**
- `backend/src/workers/eliWorker.ts` - dedykowany worker dla ELI
- `backend/src/workers/rssWorker.ts` - dedykowany worker dla RSS
- `backend/src/workers/nfzWorker.ts` - dedykowany worker dla NFZ
- `backend/src/services/workerManager.ts` - orchestrator

**Architektura workera:**
```typescript
// backend/src/workers/eliWorker.ts
export class ELIWorker {
  private scheduler: NodeCron.ScheduledTask;
  
  async start() {
    // Pierwsz y run
    await this.run();
    
    // Harmonogram: co 10 min
    this.scheduler = cron.schedule('*/10 * * * *', () => this.run());
  }
  
  private async run() {
    const sources = getELISources(); // 7 ≈∫r√≥de≈Ç
    const results = await Promise.allSettled(
      sources.map(s => this.scrapeSingleSource(s))
    );
    
    // Zapisz do DB z deduplikacjƒÖ
    for (const result of results) {
      if (result.status === 'fulfilled') {
        await this.saveToDB(result.value);
      }
    }
  }
  
  private async saveToDB(facts: LegalFact[]) {
    for (const fact of facts) {
      await prisma.legalFact.upsert({
        where: { compositeKey: fact.compositeKey },
        update: { title: fact.title, updatedAt: new Date() },
        create: fact
      });
    }
  }
}
```

### Faza 3: Nowe Endpointy API (45 min)

**Modyfikacje:**
- `backend/src/routes/api.ts` - dodaj 3 nowe endpointy

```typescript
// GET /api/v1/updates/eli
router.get('/updates/eli', async (req, res) => {
  const { range, source } = req.query;
  const where = { 
    ingestMethod: 'eli',
    ...(source && { sourceId: source }),
    ...(range && { date: { gte: getDateCutoff(range) } })
  };
  const data = await prisma.legalFact.findMany({ where, orderBy: { date: 'desc' } });
  res.json(data);
});

// GET /api/v1/updates/rss (analogicznie)
// GET /api/v1/updates/nfz (analogicznie)
```

### Faza 4: Rozszerzenie Okna Czasowego (15 min)

**Modyfikacje:**
- `backend/src/scrapers/eli/eliClient.ts:39` - zmie≈Ñ `30` ‚Üí `150`
- `backend/src/scrapers/sejmApiScraper.ts:51` - zmie≈Ñ `90` ‚Üí `150`
- `backend/src/scrapers/rssScraper.ts` - dodaj filtr `-150 dni`

**Walidacja:**
```bash
# Sprawd≈∫ najstarszy dokument w bazie
sqlite3 backend/legal.db "SELECT MIN(date) FROM LegalFact;"
# Powinno byƒá: 2025-08-05 (150 dni wstecz od 2026-01-02)
```

### Faza 5: Frontend - Nowe Filtry i UI (90 min)

**Modyfikacje:**
- `App.tsx` - dodaj prze≈ÇƒÖcznik ≈∫r√≥de≈Ç (All / ELI / RSS / NFZ)
- `services/apiService.ts` - dodaj funkcje `fetchELIUpdates()`, `fetchRSSUpdates()`, `fetchNFZUpdates()`
- Dodaj wska≈∫niki statusu per ≈∫r√≥d≈Ço (zielone/czerwone kropki)

**Nowy UI:**
```tsx
<div className="source-selector">
  <button onClick={() => setSource('all')}>Wszystkie</button>
  <button onClick={() => setSource('eli')}>ELI (7 ≈∫r√≥de≈Ç)</button>
  <button onClick={() => setSource('rss')}>RSS (2 ≈∫r√≥d≈Ça)</button>
  <button onClick={() => setSource('nfz')}>NFZ Scraper</button>
</div>

<div className="source-health">
  {sources.map(s => (
    <div key={s.id}>
      <StatusDot color={s.healthy ? 'green' : 'red'} />
      {s.name} - ostatnie pobieranie: {s.lastFetch}
    </div>
  ))}
</div>
```

### Faza 6: Monitoring i Observability (30 min)

**Nowe pliki:**
- `backend/src/services/healthService.ts` - health checks per worker
- `backend/src/types/health.ts` - typy dla status√≥w

**Endpoint:**
```typescript
// GET /api/v1/health/detailed
{
  "overall": "healthy",
  "workers": {
    "eli": { "status": "running", "lastRun": "2026-01-02T14:30:00Z", "documentsToday": 45 },
    "rss": { "status": "running", "lastRun": "2026-01-02T14:28:00Z", "documentsToday": 12 },
    "nfz": { "status": "running", "lastRun": "2026-01-02T14:25:00Z", "documentsToday": 3 }
  },
  "database": {
    "totalDocuments": 1245,
    "oldestDocument": "2025-08-05",
    "newestDocument": "2026-01-02"
  }
}
```

---

## üß™ Plan Testowania

### Unit Tests (Backend)
- `workers/eliWorker.test.ts` - testuj deduplikacjƒô
- `workers/rssWorker.test.ts` - testuj parsowanie XML
- `workers/nfzWorker.test.ts` - testuj scraping HTML

### Integration Tests
- `api/updates-eli.test.ts` - endpoint /updates/eli
- `api/updates-rss.test.ts` - endpoint /updates/rss
- `api/updates-nfz.test.ts` - endpoint /updates/nfz

### E2E Tests (Frontend)
- `e2e/source-filter.spec.ts` - prze≈ÇƒÖczanie miƒôdzy ≈∫r√≥d≈Çami
- `e2e/health-status.spec.ts` - wy≈õwietlanie status√≥w
- `e2e/date-range.spec.ts` - filtry 7d/30d/90d

---

## üìä Metryki Sukcesu

| Metryka | Obecny Stan | Cel (v2.0) | Metoda Pomiaru |
|---------|-------------|------------|----------------|
| Czas refresh (backend) | 15-32s | <10s | Logi timestamp√≥w |
| Duplikaty w bazie | ~15-20% | 0% | SQL query GROUP BY |
| Pokrycie historiƒÖ | 30-90 dni | 150 dni | MIN(date) w bazie |
| Dostƒôpno≈õƒá endpoint√≥w | 85% (blokowanie) | 99% | Health checks |
| Czas odpowiedzi API | <2s (gdy nie refreshuje) | <500ms | Middleware timing |
| Frontend load time | 3-5s | <2s | Lighthouse |

---

## üöÄ Timeline

| Faza | Czas | Blokery | Krytyczne |
|------|------|---------|-----------|
| Faza 1 (DB) | 30 min | Brak | ‚úÖ |
| Faza 2 (Workers) | 60 min | Faza 1 | ‚úÖ |
| Faza 3 (API) | 45 min | Faza 2 | ‚úÖ |
| Faza 4 (Okno) | 15 min | Brak | ‚úÖ |
| Faza 5 (Frontend) | 90 min | Faza 3 | ‚ö†Ô∏è |
| Faza 6 (Monitoring) | 30 min | Brak | ‚ö†Ô∏è |

**≈ÅƒÖczny czas:** ~4.5h  
**Krytyczna ≈õcie≈ºka:** Faza 1 ‚Üí 2 ‚Üí 3 ‚Üí 5 (3h 45min)

---

## üíæ Backup Strategy

Przed ka≈ºdƒÖ fazƒÖ:
```bash
# 1. Backup bazy danych
cp backend/legal.db backend/legal.db.backup-$(date +%Y%m%d-%H%M%S)

# 2. Git commit
git add .
git commit -m "Pre-phase-X: Backup before refactoring"

# 3. Backup .env (je≈õli istnieje)
cp backend/.env backend/.env.backup
```

---

## üìù Changelog

### v2.0 (2026-01-02) - Multi-Worker Refactoring
- ‚úÖ Rozdzielenie scraper√≥w na 3 niezale≈ºne workery
- ‚úÖ Deduplikacja z unique constraint (sourceId + docId + date)
- ‚úÖ Rozszerzenie okna czasowego do 150 dni
- ‚úÖ 3 nowe endpointy (/updates/eli, /updates/rss, /updates/nfz)
- ‚úÖ Health checks per worker
- ‚úÖ Frontend z prze≈ÇƒÖcznikiem ≈∫r√≥de≈Ç

### v1.0 (2025-12-20) - Initial Release
- 10 ≈∫r√≥de≈Ç danych (ELI + RSS + Scrapers)
- Prisma ORM + SQLite
- Scheduler co 10 minut
- Frontend React + Vite

---

**Koniec analizy**
